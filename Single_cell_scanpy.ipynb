{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single cell analysis using scanpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scanpy as sc\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting random seed\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading raw samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_raw_files = \"/path/to/Raw_Files/\"\n",
    "files = os.listdir(path_to_raw_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the AnnData objects\n",
    "mouse_sorted_ECs_list = []\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(path_to_raw_files, file)\n",
    "    \n",
    "    # Read 10X data (assuming matrix.mtx and barcodes, features files are in the subdirectories)\n",
    "    data = sc.read_10x_mtx(file_path)\n",
    "    \n",
    "    # Create AnnData object (equivalent to Seurat object)\n",
    "    adata = sc.AnnData(data.X)\n",
    "    \n",
    "    # Assign project name (Seurat's 'project' is equivalent to naming the AnnData object)\n",
    "    adata.obs['project'] = file\n",
    "    \n",
    "    # Rename cells by combining the original identifier with rownames (cell barcodes)\n",
    "    adata.obs_names = [f\"{file}_{cell}\" for cell in adata.obs_names]\n",
    "    \n",
    "    # Append the AnnData object to the list\n",
    "    mouse_sorted_ECs_list.append(adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding mito and ribo percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate mito and ribo gene percentages\n",
    "def add_mito_ribo(adata, mito_prefix=\"Mt-\", ribo_prefix=\"Rb-\"):\n",
    "    mito_genes = adata.var_names.str.startswith(mito_prefix)\n",
    "    ribo_genes = adata.var_names.str.startswith(ribo_prefix)\n",
    "    \n",
    "    adata.obs['percent_mito'] = np.sum(adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1 * 100\n",
    "    adata.obs['percent_ribo'] = np.sum(adata[:, ribo_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1 * 100\n",
    "    \n",
    "    return adata\n",
    "\n",
    "# Apply the function to each AnnData object in the list\n",
    "mouse_sorted_ECs_list = [add_mito_ribo(adata) for adata in mouse_sorted_ECs_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata in mouse_sorted_ECs_list:\n",
    "    sc.pl.violin(adata, ['n_counts', 'n_genes', 'percent_mito', 'percent_ribo'], \n",
    "                 jitter=0.4, multi_panel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata in mouse_sorted_ECs_list:\n",
    "    sc.pl.scatter(adata, x='n_counts', y='n_genes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store each AnnData object with its filename as the key\n",
    "mouse_sorted_ECs_dict = {file: adata for file, adata in zip(files, mouse_sorted_ECs_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access each object by referencing it through the dictionary, like mouse_sorted_ECs_dict['filename']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filtering low-quality cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting based on nCount_RNA, nFeature_RNA, and mitochondrial percentage\n",
    "HFD_Epi_A = HFD_Epi_A[(HFD_Epi_A.obs['n_counts'] > 200) & \n",
    "                      (HFD_Epi_A.obs['n_counts'] < 7500) &\n",
    "                      (HFD_Epi_A.obs['n_genes'] > 200) & \n",
    "                      (HFD_Epi_A.obs['n_genes'] < 3000) & \n",
    "                      (HFD_Epi_A.obs['percent_mito'] < 20), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing ribosomal/mito/other genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ribosomal genes (starting with Rp[l|s])\n",
    "raw_sample_list_NoRibo = {name: adata[:, ~adata.var_names.str.contains('^RP[L|S]', regex=True)] \n",
    "                          for name, adata in Mouse_sorted_ECs_list.items()}\n",
    "\n",
    "# Remove mitochondrial genes (starting with mt-)\n",
    "raw_sample_list_NoRbMt = {name: adata[:, ~adata.var_names.str.startswith('MT-')] \n",
    "                          for name, adata in raw_sample_list_NoRibo.items()}\n",
    "\n",
    "# Remove long non-coding RNAs (Malat1, Neat1)\n",
    "raw_sample_list_NoRbMt_lnc = {name: adata[:, ~adata.var_names.str.contains('^MALAT1|NEAT1', regex=True)] \n",
    "                              for name, adata in raw_sample_list_NoRbMt.items()}\n",
    "\n",
    "hemoglobin_genes = [\"HBB\", \"HBG2\", \"HBZ\", \"HBA2\", \"HBA1\",\n",
    "                    \"HBM\", \"HBD\", \"HBE1\", \"HBQ1\", \"HBG1\"]\n",
    "\n",
    "# Apply the filtering function to exclude hemoglobin genes\n",
    "raw_sample_list_NoRbMt_genes = {name: adata[:, ~adata.var_names.isin(hemoglobin_genes)] \n",
    "                                for name, adata in raw_sample_list_NoRbMt_lnc.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing cells using lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get log-transformed nFeature_RNA and nCount_RNA\n",
    "log_nFeature_RNA = np.log(HFD_Epi_A.obs['n_genes'])\n",
    "log_nCount_RNA = np.log(HFD_Epi_A.obs['n_counts'])\n",
    "\n",
    "# Fit a linear model using statsmodels\n",
    "X = sm.add_constant(log_nCount_RNA)  # Adds an intercept to the model\n",
    "model = sm.OLS(log_nFeature_RNA, X).fit()\n",
    "\n",
    "# Get residuals\n",
    "residuals = model.resid\n",
    "\n",
    "# Filter cells with residuals >= -0.5\n",
    "tokeep = residuals[residuals >= -0.5].index\n",
    "HFD_Epi_A = HFD_Epi_A[tokeep, :]\n",
    "\n",
    "# Plotting\n",
    "plt.scatter(log_nCount_RNA, log_nFeature_RNA, c='grey', label='All cells', s=10)\n",
    "plt.plot(log_nCount_RNA, model.fittedvalues, color='red', linewidth=3, label='Linear fit')\n",
    "plt.scatter(log_nCount_RNA.loc[tokeep], log_nFeature_RNA.loc[tokeep], c='blue', label='Filtered cells', s=20)\n",
    "plt.xlabel('log(nCount_RNA)')\n",
    "plt.ylabel('log(nFeature_RNA)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "\n",
    "# Merge multiple AnnData objects\n",
    "Merged_raw_object = HFD_Epi_A.concatenate(HFD_Epi_B, HFD_Mes_A, HFD_Mes_B, \n",
    "                                          NC_Epi_A, NC_Epi_B, NC_Mes_A, NC_Mes_B, \n",
    "                                          index_unique=None)  # Don't append object names to index\n",
    "\n",
    "# Display merged object\n",
    "print(Merged_raw_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving merged objecct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated AnnData object if needed\n",
    "adata.write('adata.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding metadata info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert .obs to a pandas DataFrame\n",
    "df_Merged_raw_object = Merged_raw_object.obs.copy()\n",
    "\n",
    "# Select relevant columns (assuming Mt_Rb is present)\n",
    "df_Merged_raw_object = df_Merged_raw_object[['orig.ident', 'n_counts', 'n_genes', 'percent_mito', 'Mt_Rb']]\n",
    "\n",
    "# Add \"Condition\" column based on \"orig.ident\"\n",
    "df_Merged_raw_object['Condition'] = df_Merged_raw_object['orig.ident']\n",
    "\n",
    "# Replace Condition values based on orig.ident\n",
    "df_Merged_raw_object['Condition'] = df_Merged_raw_object['Condition'].replace(\n",
    "    {'NC_Epi_A': 'NC', 'NC_Epi_B': 'NC', 'NC_Mes_A': 'NC', 'NC_Mes_B': 'NC', \n",
    "     'HFD_Epi_A': 'HFD', 'HFD_Epi_B': 'HFD', 'HFD_Mes_A': 'HFD', 'HFD_Mes_B': 'HFD'})\n",
    "\n",
    "# Add \"Depot\" column based on \"orig.ident\"\n",
    "df_Merged_raw_object['Depot'] = df_Merged_raw_object['orig.ident']\n",
    "\n",
    "# Replace Depot values based on orig.ident\n",
    "df_Merged_raw_object['Depot'] = df_Merged_raw_object['Depot'].replace(\n",
    "    {'NC_Epi_A': 'Epi', 'NC_Epi_B': 'Epi', 'HFD_Epi_A': 'Epi', 'HFD_Epi_B': 'Epi',\n",
    "     'NC_Mes_A': 'Mes', 'NC_Mes_B': 'Mes', 'HFD_Mes_A': 'Mes', 'HFD_Mes_B': 'Mes'})\n",
    "\n",
    "# Show updated DataFrame\n",
    "df_Merged_raw_object.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_In_House is a DataFrame in Python\n",
    "df_In_House['BMI'] = df_In_House['orig.ident']\n",
    "\n",
    "# Update BMI based on the presence of 'SAT9' in the 'orig.ident' column\n",
    "df_In_House['BMI'] = df_In_House['BMI'].replace(to_replace=r'SAT9', value='39.5', regex=True)\n",
    "\n",
    "# Show updated df_In_House\n",
    "df_In_House.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a column from existing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate 'Study' and 'Chemistry' columns to create 'Study_chemistry'\n",
    "All_Data_Atlas['Study_chemistry'] = All_Data_Atlas['Study'] + '_' + All_Data_Atlas['Chemistry']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(All_Data_Atlas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change a column into categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['louvain'] = adata.obs['louvain'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show categories (factor levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adata.obs['louvain'].cat.categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One column\n",
    "adata.obs['louvain'] = adata.obs['louvain'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multiple columns\n",
    "for col in adata.obs.select_dtypes(['category']).columns:\n",
    "    adata.obs[col] = adata.obs[col].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding cell cycle info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# URL of the cell cycle gene list\n",
    "url = \"https://raw.githubusercontent.com/hbc/tinyatlas/master/cell_cycle/Homo_sapiens.csv\"\n",
    "\n",
    "# Download the file and read into a DataFrame\n",
    "response = requests.get(url)\n",
    "cell_cycle_genes = pd.read_csv(pd.compat.StringIO(response.text))\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(cell_cycle_genes.head())\n",
    "\n",
    "\n",
    "from biomart import BiomartServer\n",
    "\n",
    "# Connect to Biomart server\n",
    "server = BiomartServer('http://www.ensembl.org/biomart')\n",
    "mart = server.datasets['hsapiens_gene_ensembl']\n",
    "\n",
    "# Get gene annotations\n",
    "attributes = [\n",
    "    'ensembl_gene_id', 'external_gene_name', 'chromosome_name', \n",
    "    'gene_biotype', 'description'\n",
    "]\n",
    "annotations = mart.query(attributes=attributes)\n",
    "annotations = annotations.to_dataframe()\n",
    "\n",
    "# Display the first few rows\n",
    "print(annotations.head())\n",
    "\n",
    "\n",
    "# Merge cell cycle genes with annotations\n",
    "cell_cycle_markers = pd.merge(cell_cycle_genes, annotations, left_on='geneID', right_on='ensembl_gene_id')\n",
    "\n",
    "# Get S phase genes\n",
    "s_genes = cell_cycle_markers[cell_cycle_markers['phase'] == 'S']['external_gene_name'].tolist()\n",
    "\n",
    "# Get G2M phase genes\n",
    "g2m_genes = cell_cycle_markers[cell_cycle_markers['phase'] == 'G2/M']['external_gene_name'].tolist()\n",
    "\n",
    "\n",
    "# Perform cell cycle scoring\n",
    "sc.tl.score_genes(adata, gene_list=s_genes, score_name='S_score')\n",
    "sc.tl.score_genes(adata, gene_list=g2m_genes, score_name='G2M_score')\n",
    "\n",
    "# Display the first few rows of the updated metadata\n",
    "print(adata.obs.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the expression of specific features\n",
    "sc.pl.umap(adata, color=['ncount', 'ngenes'])  # Assuming 'nCount_RNA' and 'nFeature_RNA' are present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-normalizing the data (similar to LogNormalize in Seurat)\n",
    "sc.pp.normalize_total(adata, target_sum=10000)\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highly variable genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding highly variable genes\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "sc.pp.scale(adata)  # You can also add options like `max_value`\n",
    "\n",
    "## Regressing out variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running PCA\n",
    "sc.tl.pca(adata, svd_solver='arpack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elbow plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow plot\n",
    "sc.pl.pca_variance_ratio(adata, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Significant PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the explained variance ratio for each PC\n",
    "pct = adata.uns['pca']['variance_ratio'] * 100\n",
    "cum = pct.cumsum()\n",
    "co1 = (cum > 90).argmax() + 1  # First component where cumulative variance exceeds 90%\n",
    "co2 = (pct[1:] - pct[:-1] > 0.05).nonzero()[0].max() + 2\n",
    "pcs = min(co1, co2)\n",
    "sig_pcs = list(range(1, pcs+1))  # Significant PCs\n",
    "print(sig_pcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find neighbors using significant PCs\n",
    "sc.pp.neighbors(adata, n_pcs=pcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run UMAP\n",
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(adata)  # Plot UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Integration using harmony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import harmonypy as hm\n",
    "\n",
    "# Assuming 'adata' is the AnnData object and 'orig.ident' is stored in 'adata.obs'\n",
    "harmony_integrator = hm.HarmonyIntegrator(X=adata.obsm['X_pca'], meta_data=adata.obs['orig.ident'])\n",
    "harmony_integrator.run()\n",
    "\n",
    "# Add harmony embedding to the AnnData object\n",
    "adata.obsm['X_harmony'] = harmony_integrator.Z_corr.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Significant harmony components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the explained variance ratio of Harmony components\n",
    "pct = harmony_integrator.vars_ / harmony_integrator.vars_.sum() * 100\n",
    "cum = pct.cumsum()\n",
    "co1 = (cum > 90).argmax() + 1\n",
    "co2 = (pct[1:] - pct[:-1] > 0.05).nonzero()[0].max() + 2\n",
    "pcs = min(co1, co2)\n",
    "harmony_sig_pcs = list(range(1, pcs + 1))\n",
    "print(harmony_sig_pcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running UMAP using the Harmony dimensions\n",
    "sc.pp.neighbors(adata, use_rep='X_harmony', n_pcs=pcs)\n",
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(adata, color=['orig.ident'], legend_loc='on data')  # You can label points if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gene Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Excel file\n",
    "ECs_markers_ref = pd.read_excel(\"/home/lucamannino/Downloads/Vascular_markers_summary.xlsx\", sheet_name=0)\n",
    "\n",
    "# Splitting 'Capillary.ECs' column into two\n",
    "ECs_markers_ref[['Capillary.ECs', '_']] = ECs_markers_ref['Capillary.ECs'].str.split(' ', expand=True)\n",
    "ECs_markers_ref.drop(columns='_', inplace=True)\n",
    "\n",
    "# Removing NaN values\n",
    "ECs_markers_ref_cleaned = {col: ECs_markers_ref[col].dropna().tolist() for col in ECs_markers_ref.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding signature\n",
    "from itertools import chain\n",
    "\n",
    "for cell_type, gene_list in ECs_markers_ref_cleaned.items():\n",
    "    # Compute the module score for each cell type\n",
    "    sc.tl.score_genes(adata, gene_list, score_name=f'{cell_type}_signature')\n",
    "\n",
    "# Rename columns to match the Seurat format if needed\n",
    "adata.obs.columns = adata.obs.columns.str.replace('_signature1$', '_signature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract signature columns\n",
    "\n",
    "# Extract columns with '_signature' in their names\n",
    "signature_columns = [col for col in adata.obs.columns if col.endswith('_signature')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the feature expression of each signature column\n",
    "sc.pl.umap(adata, color=signature_columns, ncols=3, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolutions = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "# Perform clustering for different resolutions\n",
    "for res in resolutions:\n",
    "    sc.tl.leiden(adata, resolution=res, key_added=f'leiden_{res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters identified by the Leiden algorithm across different resolutions\n",
    "snn_columns = [col for col in adata.obs.columns if col.startswith('leiden')]\n",
    "sc.pl.umap(adata, color=snn_columns, ncols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set identity based on a specific resolution (e.g., res=0.3)\n",
    "adata.obs['leiden_0.3'] = adata.obs['leiden_0.3'].astype('category')\n",
    "adata.obs['leiden_0.3'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding marker genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find marker genes\n",
    "sc.tl.rank_genes_groups(adata, groupby='leiden_0.3', method='wilcoxon', min_in_group_fraction=0.15, logfc_min=0.3)\n",
    "\n",
    "# Get the top 50 and 100 marker genes per cluster\n",
    "markers_df = sc.get.rank_genes_groups_df(adata, group='all')\n",
    "\n",
    "# Top 50 genes per cluster\n",
    "top50 = markers_df.groupby('group').apply(lambda x: x.nlargest(50, 'logfoldchanges')).reset_index(drop=True)\n",
    "\n",
    "# Top 100 genes per cluster\n",
    "top100 = markers_df.groupby('group').apply(lambda x: x.nlargest(100, 'logfoldchanges')).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting marker gene list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save as Excel\n",
    "markers_df.to_excel(\"markers_Vascular_WRST_15PCT_Log03_res02.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new names for clusters\n",
    "new_names = {\n",
    "    '0': '', \n",
    "    '1': '', \n",
    "    '2': '', \n",
    "    '3': '',\n",
    "    '4': '',\n",
    "    '5': '',\n",
    "    '6': ''}\n",
    "\n",
    "# Recode identities\n",
    "adata_subset.obs['WAT_Vascular_labels'] = adata_subset.obs['leiden_0.3'].replace(new_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster subset (exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset data to subset cluster '11'\n",
    "adata_subset = adata[adata.obs['leiden_0.3'] == '11'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster subset (inclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vascular_cells = adata[adata.obs['RNA_snn_res.0.5'].isin(['4', '6', '7', '11', '12', '13', '14', '24', '27'])]\n",
    "vascular_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster subset (exclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset data to exclude cluster '11'\n",
    "adata_subset = adata[adata.obs['leiden_0.3'] != '11'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving all objects in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "# Get all objects in the global namespace\n",
    "all_objects = {name: obj for name, obj in globals().items() if not name.startswith('__') and not callable(obj)}\n",
    "\n",
    "# Save all objects to a file\n",
    "with open('my_workspace.pkl', 'wb') as file:\n",
    "    pickle.dump(all_objects, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import types\n",
    "\n",
    "def is_pickleable(obj):\n",
    "    \"\"\"Check if an object can be pickled.\"\"\"\n",
    "    try:\n",
    "        pickle.dumps(obj)\n",
    "    except (pickle.PicklingError, TypeError, AttributeError):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def is_global(obj_name, obj):\n",
    "    \"\"\"Check if an object is globally accessible and not a local function or method.\"\"\"\n",
    "    return isinstance(obj, (types.ModuleType, types.FunctionType)) is False and not obj_name.startswith('__')\n",
    "\n",
    "# Get all pickleable and globally accessible objects in the global namespace\n",
    "pickleable_objects = {\n",
    "    name: obj for name, obj in globals().items()\n",
    "    if is_global(name, obj) and is_pickleable(obj)\n",
    "}\n",
    "\n",
    "# Save pickleable objects to a file\n",
    "with open('workspace.pkl', 'wb') as file:\n",
    "    pickle.dump(pickleable_objects, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading an environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load all objects from a file\n",
    "with open('my_workspace.pkl', 'rb') as file:\n",
    "    loaded_objects = pickle.load(file)\n",
    "\n",
    "# Restore all objects to the global namespace\n",
    "globals().update(loaded_objects)\n",
    "\n",
    "# Verify objects are loaded\n",
    "print(loaded_objects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
